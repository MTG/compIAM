{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aeb55fb",
   "metadata": {},
   "source": [
    "# Melodic Pattern Recognition in Carnatic Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5ba416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d55d7b",
   "metadata": {},
   "source": [
    "Melodic patterns (motifs and phrases), known as sañcāras, play a crucial structural and expressive role in Carnatic Music. These melodic patterns are the means through which the character of the rāga is expressed and form the basis of various improvisatory and compositional formats in the style [2,9]. There exists no definitive lists of all possible sañcāras in each rāga, rather the body of existing compositions and the living oral tradition of rāga performance act as repositories for that knowledge.\n",
    "\n",
    "This notebook will walk through the task of identifying and annotating sañcāras from audio using the compIAM tools repository.\n",
    "\n",
    "The methodology follows that presented in _Nuttall, Thomas, Genís Plaja-Roglans, Lara Pearson, and Xavier Sierra. \"In search of Sañcāras: tradition-informed repeated melodic pattern recognition in carnatic music.\" (2022)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiam import load_model\n",
    "from compiam.visualisation.waveform_player import Player\n",
    "from compiam.melody.pattern.sancara_search.extraction.evaluation import load_annotations_brindha, to_aeneas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8fea0",
   "metadata": {},
   "source": [
    "## 1. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf32f6d",
   "metadata": {},
   "source": [
    "We use as an example a performance of insert_raga_here by insert_performer_here, in the raga, insert_raga_here. From the saraga dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa3bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/Volumes/Shruti/asplab2/cae-invar/audio/multitrack/Sharanu Janakana.mp3\"\n",
    "title = 'Sharanu Janakana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eafc6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e27152691df4278b630fe50f5556e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Player(value='<iframe srcdoc=\"&lt;!DOCTYPE html&gt;\\n&lt;html lang=&quot;en&quot;&gt;\\n  &lt;head&gt;\\n  &lt;m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Player(title, audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763bb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe include: Source separation?\n",
    "\n",
    "# TODO, for each stage include a visualisation [VIS]\n",
    "# [VIS] Audio waveform and playback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441b9ee",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126a6c3",
   "metadata": {},
   "source": [
    "Two feature sets are extracted from each recording in SCV: (1) An automated transcription of the predominant sung pitch in Cents from which we derive a mask corresponding to silent/stable regions, and (2) Transformation-invariant melodic features extracted using a Complex Autoencoder (CAE) from audio in CQT representation, which we use for self-similarity computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df55b1",
   "metadata": {},
   "source": [
    "### 2.1 Predominant Pitch Track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a757d65",
   "metadata": {},
   "source": [
    "Load FTA-Net predominant pitch extraction trained on carnatic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftanet = load_model('melody:ftanet-carnatic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140be70",
   "metadata": {},
   "source": [
    "Extract predominant pitch track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711627ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_track = ftanet.predict(audio_path)\n",
    "pitch = pitch_track[:,1]\n",
    "time  = pitch_track[:,0]\n",
    "timestep  = time[2]-time[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [VIS] Pitch track + waveform + audio playback\n",
    "\n",
    "# Pitch distribution using pypeaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6e17a",
   "metadata": {},
   "source": [
    "Relative to other musical styles, Carnatic Music is heavily ornamented. This ornamentation is not superficial decoration but rather is integral to musical meaning [2]. The ornaments, known as gamakas, can greatly alter the sound of the notated svaras (notes); for example, some gamakas do not rest at all on the theoretical pitch of the notated svara, and instead involve oscillations between pitches either side of it [3,4]. This oscillatory movement is particularly characteristic of the style, and can often subsume individual svaras [4]. The surface effect on the melodic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7078e45",
   "metadata": {},
   "source": [
    "#### 2.1.1 Silence and Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability Track\n",
    "from compiam.utils.pitch import extract_stability_mask\n",
    "import numpy as np\n",
    "\n",
    "stability_mask = extract_stability_mask(\n",
    "    pitch=pitch, \n",
    "    min_stab_sec=1.0, \n",
    "    hop_sec=0.2,\n",
    "    var=60,\n",
    "    timestep=timestep)\n",
    "\n",
    "# Silence Mask\n",
    "silence_mask = pitch==0\n",
    "\n",
    "exclusion_mask = np.logical_or(silence_mask==1, stability_mask==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec4704",
   "metadata": {},
   "source": [
    "#### 2.1.2 Visualising Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2453d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch curve\n",
    "# Load expected notes for this svara\n",
    "# Can you see more peaks than svaras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804372a6",
   "metadata": {},
   "source": [
    "### 2.2 Melodic Feature Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad049518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Extraction for a Given Audio\n",
    "from compiam import load_model\n",
    "\n",
    "# Feature Extraction\n",
    "# CAE features \n",
    "cae = load_model(\"melody:cae-carnatic\")\n",
    "\n",
    "ampl, phase = cae.extract_features(audio_path)\n",
    "\n",
    "# [VIS] Feature activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285facf",
   "metadata": {},
   "source": [
    "#### 2.2.1 Self Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [VIS] Stability and silence annotation\n",
    "\n",
    "# Self Similarity\n",
    "from compiam.melody.pattern import self_similarity\n",
    "\n",
    "ss = self_similarity(ampl, exclusion_mask=exclusion_mask, timestep=timestep, hop_length=cae.hop_length, sr=cae.sr)\n",
    "X, orig_sparse_lookup, sparse_orig_lookup, boundaries_orig, boundaries_sparse = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [VIS] Self similarity matrix\n",
    "# [VIS] Self similarity matrix with boundaries annotated\n",
    "# [VIS] Self similarity matrix full silent and stable regions annotated\n",
    "\n",
    "# Segment Extraction\n",
    "\n",
    "# Segment Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefa534",
   "metadata": {},
   "source": [
    "## Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fa513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compiam",
   "language": "python",
   "name": "compiam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
